# სახლების ფასების პროგნოზირება

## Kaggle-ის კონკურსის მოკლე მიმოხილვა
ეს პროექტი წარმოადგენს Kaggle-ის კონკურსს "House Prices - Advanced Regression Techniques"-ს. კონკურსის მიზანია სახლების ფასების პროგნოზირება მათი სხვადასხვა მახასიათებლების საფუძველზე. 

## ჩემი მიდგომა პრობლემის გადასაჭრელად
პრობლემის გადასაჭრელად გამოვიყენე მიდგომა, რომელიც მოიცავდა შემდეგ ეტაპებს:

1. **მონაცემების შესწავლა და ანალიზი (EDA)** - მონაცემების სტრუქტურის, განაწილებების და ცვლადებს შორის ურთიერთობების გასაგებად
2. **მონაცემების გაწმენდა** - Nan მნიშვნელობების დამუშავება და არარელევანტური Feature-ბის ამოღება
3. **Feature Engineering** - კატეგორიული ცვლადების გარდაქმნა და იშვიათი კატეგორიების დაჯგუფება
4. **Feature Selection** - ყველაზე მნიშვნელოვანი Feature-ების იდენტიფიცირება მოდელის პერფორმანის გასაუმჯობესებლად
5. **მოდელის ტრენინგი და შეფასება** - რამდენიმე რეგრესიული მოდელის გამოცდა და შედარება
6. **ჰიპერპარამეტრების ოპტიმიზაცია** - საუკეთესო მოდელის პარამეტრების გაუმჯობესება
7. **პროგნოზირება** - საბოლოო მოდელის გამოყენება სატესტო მონაცემებზე პროგნოზებისთვის

მთელი პროცესის განმავლობაში MLflow გამოვიყენე ექსპერიმენტების დასათრექად, ფიჩერ სელექშენისთვის გამოვიყენე ორი მიდგომა:
1. **LinerRegression**
2. **RandomForestRegressor**
მეორემ უკეთესი შედეგი მომცა შემდგომ მოდელების ევალუაციისას (ალბათ ჯობდა ესეც დამეთრექა MLFlow-ზე მაგრამ დალოგვა ბოლოს დავაიმპლემენტირე..)

## რეპოზიტორიის სტრუქტურა

### ფაილების განმარტება
- **model_experiment.ipynb** - ძირითადი ნოუთბუქი, რომელიც მოიცავს მონაცემთა გაწმენდას, Feature Engineering-ს, Feature Selection-ს და მოდელის ტრენინგს
- **model_inference.ipynb** - ასრულებს პროგნოზირებას სატესტო მონაცემებზე MLflow-ს მოდელების რეესტრიდან საუკეთესო მოდელის გამოყენებით
- **README.md** - პროექტის დოკუმენტაცია (ეს ფაილი)

## Data Cleaning

### დატასეტი გავასუფთავე ისეთი სვეტებისგან, რომლებსაც ჰქონდა ნახევარზე მეტი Nan მნიშვნელობა. 
ამის შემდგომ კატეგორიული ცვლადები შევცვალე მოდით, რიცხვითი ცვლადები საშუალოთი.
ბოლოს პლოტებზე დაკვირვებით დავდროფე ისეთი სვეტები, რომლებსაც ან მცირედი გავლენა ჰქონდა ფასზე, ან მხოლოდ 1 კატეგორია საგრძნობლად დომინირებდა.

## Feature Engineering

### კატეგორიული ცვლადების რიცხვითში გადაყვანა
კატეგორიული ცვლადების დასამუშავებლად გამოვიყენე რამდენიმე მიდგომა:


1. **იშვიათი კატეგორიების დაჯგუფება** - კატეგორიები, რომლებიც გვხვდება  1%-ზე ნაკლები, გავაერთიანე 'Other' კატეგორიაში. ეს ეხმარება მოდელს, რომ არ მოერგოს ზედმეტად იშვიათ შემთხვევებს და ამცირებს კატეგორიული ცვლადების განზომილებას.

```python
threshold = df.shape[0] * 0.01
for col in categorical_columns:
    category_counts = df[col].value_counts()
    rare_categories = category_counts[category_counts < threshold].index
    df[col] = df[col].apply(lambda x: 'Other' if x in rare_categories else x)
```

2. **Label Encoding** - კატეგორიული ცვლადებისთვის გამოვიყენე LabelEncoder, რომელიც თითოეულ კატეგორიას ანიჭებს უნიკალურ მთელ რიცხვს. ეს მიდგომა გამოვიყენე ყველა კატეგორიული ცვლადისთვის, რათა ისინი შესაბამისი იყოს  ალგორითმებისთვის.

```python
label_encoder = LabelEncoder()
for col in categorical_columns:
    train_df[col] = label_encoder.fit_transform(train_df[col])
```


## Feature Selection

Feature Selection-ისთვის გამოვიყენე რეკურსიული Feature Elimination Cross-Validation (RFECV), რათა იდენტიფიცირებული ყოფილიყო ყველაზე მნიშვნელოვანი ცვლადები. ეს მიდგომა რეკურსიულად შლის ფუნქციებს და აფასებს მოდელის წარმადობას, რათა გამოავლინოს ოპტიმალური ფუნქციების ქვესიმრავლე.

### გამოყენებული მიდგომები და მათი შეფასება

**RFECV RandomForestRegressor-ით**:
- RandomForestRegressor-ი გამოვიყენე როგორც ჩემი ფუნქციის მნიშვნელობის შემფასებელი ალგორითმი
- RFECV-მ იდენტიფიცირება გაუკეთა ოპტიმალურ ფუნქციების რაოდენობას, რომელიც საჭიროა კარგი პროგნოზირების მოდელისთვის
- RFECV-მ საშუალება მომცა შევაფასო და დავალაგო ფუნქციები მათი მნიშვნელობის მიხედვით

შედეგად, RFECV-მ აირჩია ყველაზე მნიშვნელოვანი ფიჩერები ჩემი მოდელისთვის, რომლებიც მნიშვნელოვნად შეამცირა ფუნქციების სივრცე, რამაც გააუმჯობესა მოდელის პერფორმანსი და შეამცირა overfitting-ის რისკი.

## Training

მოდელების ტრენინგისთვის გამოვიყენე სხვადასხვა რეგრესიული ალგორითმები და შევაფასე მათი შესრულება.

### ტესტირებული მოდელები

გამოვიყენე შემდეგი მოდელები:
1. **Linear Regression** 
2. **Random Forest** 
3. **Gradient Boosting**
4. **XGBoost** 

თითოეული მოდელისთვის დავთვალე შემდეგი მეტრიკები:
- Train RMSE (Root Mean Squared Error)
- Validation RMSE
- Train R²
- Validation R²
- Validation MAE (Mean Absolute Error)

შედეგები აჩვენა, რომ XGBoost მოდელი ყველაზე კარგად მუშაობდა ვალიდაციის მონაცემებზე.

### Hyperparameter ოპტიმიზაციის მიდგომა

საუკეთესო მოდელისთვის შევასრულე ჰიპერპარამეტრების ოპტიმიზაცია GridSearchCV-ის გამოყენებით. GridSearchCV იყენებს სხვადასხვა ჰიპერპარამეტრების კომბინაციას და ირჩევს საუკეთესოს.

XGBoost-ისთვის ოპტიმიზირებული ჰიპერპარამეტრები მოიცავდა:
- n_estimators: [50, 100, 200]
- learning_rate: [0.01, 0.1, 0.2]
- max_depth: [3, 5, 7]
- colsample_bytree: [0.7, 0.8, 0.9]

შედეგად მივიღე XGBoost-ის ოპტიმიზირებული ვერსია, რომელმაც აჩვენა საუკეთესო შედეგო.

### საბოლოო მოდელის შერჩევის დასაბუთება

საბოლოო მოდელად ავირჩიე XGBoost შემდეგი მიზეზების გამო:
1. მას ჰქონდა ყველაზე დაბალი ვალიდაციის RMSE ყველა გამოცდილ მოდელს შორის
2. XGBoost-ს ჰქონდა მაღალი R² მაჩვენებელი, რაც მიუთითებს კარგ შესაბამისობაზე მონაცემებთან
3. ოპტიმიზაციის შემდეგ, მოდელის გადაჭარბებული მორგების (overfitting) ნიშნები შემცირდა

## MLflow Tracking

### MLflow ექსპერიმენტების ბმული
ექსპერიმენტები ინახება DagsHub-ზე და ხელმისაწვდომია ამ ბმულზე: https://dagshub.com/lagorg22/house_prices

### ჩაწერილი მეტრიკების აღწერა

**დასუფთავების ეტაპი**:
- ორიგინალური და გაწმენდილი მონაცემების ფორმები
- ამოღებული/შევსებული სვეტების რაოდენობა
- გაწმენდის საფეხურის აღწერა

**Feature Engineering ეტაპი**:
- Feature-ების რაოდენობა Engineering-ის წინ და შემდეგ
- ახალი და ტრანსფორმირებული ფუნქციების სია
- Feature Engineering-ის ნაბიჯის აღწერა

**Feature Selection ეტაპი**:
- შერჩეული feature-ების რაოდენობა და სახელები
- Feature-ების დარანკვა მნიშვნელობის მიხედვით
- Feature-ების შემცირების პროცენტი

**მოდელის ტრენინგის ეტაპი**:
- train_rmse: ტრენინგის მონაცემებზე Root Mean Squared Error
- val_rmse: ვალიდაციის მონაცემებზე Root Mean Squared Error
- train_r2: ტრენინგის R² score
- val_r2: ვალიდაციის R² score
- train_mae: ტრენინგის Mean Absolute Error
- val_mae: ვალიდაციის Mean Absolute Error
- მოდელის ჰიპერპარამეტრები
- Feature-ების მნიშვნელობა (მოდელებისთვის, რომლებიც გვაძლევენ ამ ინფორმაციას)

### საუკეთესო მოდელის შედეგები

საუკეთესო მოდელის (ოპტიმიზირებული XGBoost) შესრულების მეტრიკები:

- **ვალიდაციის RMSE**: 23105.67
- **ვალიდაციის MAE**: 14658.21
- **ვალიდაციის R²**: 0.9121

მოდელი დარეგისტრირებულია MLflow-ის მოდელების რეესტრში და ხელმისაწვდომია inference-ისთვის `model_inference.ipynb` ფაილში.

# პ.ს.
ჩემმა სუბმიშენმა Kaggle-ზე დააფიქსირა 0.14734 შედეგი

Kaggle-ზე არ მიმუშავია, იმედია ეს არ იქნება პრობლემა... 
MLFlow-ს რაც შეეხება, თავდაპირველი ექსპერიმენტები დავაარქივე, ნაკლებად ინფორმატიული იყო. თუ საჭირო იქნება დავაბრუნებ.